{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"25e99a4b316349319ec7506ea6abaaf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ad046f44bee4ff680a74ad7c9b02028","IPY_MODEL_13138fd7a2bb4f3684de3a7d4bdcbfde","IPY_MODEL_af84931c4d884942abbb008b26aebfe4"],"layout":"IPY_MODEL_8190bb00cfbc4fd1b1b4f48dada09de1"}},"9ad046f44bee4ff680a74ad7c9b02028":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da23d5286d1c4dda96aafc71f3784a08","placeholder":"​","style":"IPY_MODEL_21ff29380b0543c0a952a0d0cbd25735","value":"vocab.json: 100%"}},"13138fd7a2bb4f3684de3a7d4bdcbfde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59e6803bb4474adeaa9e92ade7225c49","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b275fbd860d04bdd80201780f9cbf3b8","value":898823}},"af84931c4d884942abbb008b26aebfe4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c528b2ff0be4ad89fd717f663207add","placeholder":"​","style":"IPY_MODEL_9830b85dc4644e329b1f33c3e5ed1927","value":" 899k/899k [00:00&lt;00:00, 3.93MB/s]"}},"8190bb00cfbc4fd1b1b4f48dada09de1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da23d5286d1c4dda96aafc71f3784a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21ff29380b0543c0a952a0d0cbd25735":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59e6803bb4474adeaa9e92ade7225c49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b275fbd860d04bdd80201780f9cbf3b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c528b2ff0be4ad89fd717f663207add":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9830b85dc4644e329b1f33c3e5ed1927":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e8d9a8dfd2b4930b1b3f65d1267700a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5461b1ebcf2424094c1bd962d2561e4","IPY_MODEL_185a3de6c95c4b2eb6135aee70d0d53e","IPY_MODEL_76afd9ccebaa4892bfbd1a3c1b9a18ca"],"layout":"IPY_MODEL_e3edede5e76e4d3e82ae3db7a3d8292a"}},"a5461b1ebcf2424094c1bd962d2561e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9690b14bb286488aa62500a58829cc6f","placeholder":"​","style":"IPY_MODEL_66ed6cef9aa34e3f952fdf6c093c8ee9","value":"merges.txt: 100%"}},"185a3de6c95c4b2eb6135aee70d0d53e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b75ae07773d4833a19de3eee137475b","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49947fee612d4d9f83fa9d2fe4db5d73","value":456318}},"76afd9ccebaa4892bfbd1a3c1b9a18ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_603fc97e729a4e47bb89e48a8f35dc55","placeholder":"​","style":"IPY_MODEL_1d205fcf02444055a0712760fb25df36","value":" 456k/456k [00:00&lt;00:00, 26.2MB/s]"}},"e3edede5e76e4d3e82ae3db7a3d8292a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9690b14bb286488aa62500a58829cc6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ed6cef9aa34e3f952fdf6c093c8ee9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b75ae07773d4833a19de3eee137475b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49947fee612d4d9f83fa9d2fe4db5d73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"603fc97e729a4e47bb89e48a8f35dc55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d205fcf02444055a0712760fb25df36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"580f362b972e4ac7962e25978184991d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a42ff6c11c24975a9637c57598736cc","IPY_MODEL_d73332e32b254ec990711cff39bbc2e8","IPY_MODEL_e8a3dc345f9e4b1c85de8d8015a61aec"],"layout":"IPY_MODEL_4da552dab3064bda9ea998af4ce20663"}},"9a42ff6c11c24975a9637c57598736cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2b7088f15be42629eb066fe445e08e2","placeholder":"​","style":"IPY_MODEL_3418e940578d416ab0f567fc452c422e","value":"tokenizer.json: 100%"}},"d73332e32b254ec990711cff39bbc2e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaae1fbaa35d4e579764a2a5b30e608e","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c04e66b257b49eaad330f0ba0667eb3","value":1355863}},"e8a3dc345f9e4b1c85de8d8015a61aec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1c5acba14304426a82ccf6e4620fa27","placeholder":"​","style":"IPY_MODEL_8f877290acff4305a0b50df4dc32050c","value":" 1.36M/1.36M [00:00&lt;00:00, 25.7MB/s]"}},"4da552dab3064bda9ea998af4ce20663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2b7088f15be42629eb066fe445e08e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3418e940578d416ab0f567fc452c422e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aaae1fbaa35d4e579764a2a5b30e608e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c04e66b257b49eaad330f0ba0667eb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1c5acba14304426a82ccf6e4620fa27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f877290acff4305a0b50df4dc32050c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdae1c46ff884f39a7bc2de251113ce1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e56068256aa40b08fa9d98b5cbd528b","IPY_MODEL_af7ae84e373845b9845513c0e644b6a2","IPY_MODEL_f729054d9b5140aabd696558f90f32dc"],"layout":"IPY_MODEL_a89acce6a579432eb969cf599a133083"}},"6e56068256aa40b08fa9d98b5cbd528b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d66eea3965c422190245d87dd12208d","placeholder":"​","style":"IPY_MODEL_55d1c71063c748b08c3939647548e555","value":"config.json: 100%"}},"af7ae84e373845b9845513c0e644b6a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3cdcd110e5947e692ad24748a544f81","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_960e94d4513b4ba2a1e02463236b391b","value":1716}},"f729054d9b5140aabd696558f90f32dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebdd8c3b8585461cb7fc343fad89b40a","placeholder":"​","style":"IPY_MODEL_5e852771bf024007ae3b9836fbaf7fa7","value":" 1.72k/1.72k [00:00&lt;00:00, 28.3kB/s]"}},"a89acce6a579432eb969cf599a133083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d66eea3965c422190245d87dd12208d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d1c71063c748b08c3939647548e555":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3cdcd110e5947e692ad24748a544f81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"960e94d4513b4ba2a1e02463236b391b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebdd8c3b8585461cb7fc343fad89b40a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e852771bf024007ae3b9836fbaf7fa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6553531097640e9a30ef4a544a28bb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_009d1195d2df481dba00cc791d66db8a","IPY_MODEL_a2fb856bc9b043b4a90db214828eb13f","IPY_MODEL_40d050d991d345d39cfd8f4431dbf1a2"],"layout":"IPY_MODEL_fa77e8a107e24d848c734bd99014ecac"}},"009d1195d2df481dba00cc791d66db8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f2cbe4a49c644d6affdd17e613a9449","placeholder":"​","style":"IPY_MODEL_4aaa81ec184a42339ff634c266e60508","value":"Map: 100%"}},"a2fb856bc9b043b4a90db214828eb13f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_480b62486716452b9ae7f9f031fdf0bc","max":27005,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6548e32998f9418f84a3ac02c6d69fda","value":27005}},"40d050d991d345d39cfd8f4431dbf1a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54a571e996a740b4be206fecaeedbc19","placeholder":"​","style":"IPY_MODEL_6af948a861d74a60a94c8d0fbf0fba9d","value":" 27005/27005 [01:01&lt;00:00, 576.79 examples/s]"}},"fa77e8a107e24d848c734bd99014ecac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f2cbe4a49c644d6affdd17e613a9449":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aaa81ec184a42339ff634c266e60508":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"480b62486716452b9ae7f9f031fdf0bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6548e32998f9418f84a3ac02c6d69fda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54a571e996a740b4be206fecaeedbc19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af948a861d74a60a94c8d0fbf0fba9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acb2af4ae2af4015a76edef27ce358d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c699cf7cbed549be9bc1cfe174873c71","IPY_MODEL_033be642a89a4049930df32478685386","IPY_MODEL_1161eb65e8d14291bac3d0699c11956a"],"layout":"IPY_MODEL_a2a17afd637f4519a1245da858c2ff1e"}},"c699cf7cbed549be9bc1cfe174873c71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f96ef6c55a734747ba857179ca96150e","placeholder":"​","style":"IPY_MODEL_033cb27e8ac0489fbe50603c663f6775","value":"Map: 100%"}},"033be642a89a4049930df32478685386":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7dfb7ee827b4db0a3b34bedd238b47b","max":6751,"min":0,"orientation":"horizontal","style":"IPY_MODEL_454a3f67a7be4768bc39619f47fe141b","value":6751}},"1161eb65e8d14291bac3d0699c11956a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d116751f6ce3443482dfca365e25ea49","placeholder":"​","style":"IPY_MODEL_17024d77846c4c4aa66d45cf4e92a605","value":" 6751/6751 [00:12&lt;00:00, 507.14 examples/s]"}},"a2a17afd637f4519a1245da858c2ff1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f96ef6c55a734747ba857179ca96150e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"033cb27e8ac0489fbe50603c663f6775":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7dfb7ee827b4db0a3b34bedd238b47b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"454a3f67a7be4768bc39619f47fe141b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d116751f6ce3443482dfca365e25ea49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17024d77846c4c4aa66d45cf4e92a605":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53a5274736214470b8d55843b6df30c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4167910f6a0410195a65d2256f026c7","IPY_MODEL_ac1c806fd19143ddae09f94dee64fb3e","IPY_MODEL_3ea5cf8babee4d88b69a220a85a0b517"],"layout":"IPY_MODEL_2e8ce0e1d2244f3ab074f4c11280f06c"}},"f4167910f6a0410195a65d2256f026c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6662340c6ad492eba572cf413cbac6f","placeholder":"​","style":"IPY_MODEL_862b4e4c715744be811f753edf8cce57","value":"model.safetensors: 100%"}},"ac1c806fd19143ddae09f94dee64fb3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f533e91132ae479b83fe606476761214","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dce1c8bb4fcd40d8ac480df0636ae04f","value":557709915}},"3ea5cf8babee4d88b69a220a85a0b517":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb7ddf006e2d4f48982567e31d7ec36c","placeholder":"​","style":"IPY_MODEL_304c4f2814a843c9bd4b8c03704d84ea","value":" 558M/558M [00:03&lt;00:00, 133MB/s]"}},"2e8ce0e1d2244f3ab074f4c11280f06c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6662340c6ad492eba572cf413cbac6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"862b4e4c715744be811f753edf8cce57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f533e91132ae479b83fe606476761214":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce1c8bb4fcd40d8ac480df0636ae04f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb7ddf006e2d4f48982567e31d7ec36c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"304c4f2814a843c9bd4b8c03704d84ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dfe2255fac34b14acf94e76716ef7b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a0eba8df5134824a502adb518712068","IPY_MODEL_c8463a53af7c45cc947a6409dc319351","IPY_MODEL_b5ec44d3e88d4da5873d835b7448d9b4"],"layout":"IPY_MODEL_d16acbb318884408b13a4a2cae690d87"}},"5a0eba8df5134824a502adb518712068":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4447ea033ba441ceac1bbd940a9c4eac","placeholder":"​","style":"IPY_MODEL_4d23e6c83b07471f9d102704cd30b20e","value":"Downloading builder script: 100%"}},"c8463a53af7c45cc947a6409dc319351":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6df32c558a94f7b86758089f0e54ad3","max":8146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94a405ee13b44e1fae258adfc5469dc4","value":8146}},"b5ec44d3e88d4da5873d835b7448d9b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f67bd85bcc345bfbd2771ca2feef0e2","placeholder":"​","style":"IPY_MODEL_ba459dce3a464746a3644169826a47f1","value":" 8.15k/8.15k [00:00&lt;00:00, 550kB/s]"}},"d16acbb318884408b13a4a2cae690d87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4447ea033ba441ceac1bbd940a9c4eac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d23e6c83b07471f9d102704cd30b20e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6df32c558a94f7b86758089f0e54ad3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94a405ee13b44e1fae258adfc5469dc4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f67bd85bcc345bfbd2771ca2feef0e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba459dce3a464746a3644169826a47f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd92bd7a26fb4a629675880ae163b745":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac67751ea5f04c86a6f8585fbc415ec9","IPY_MODEL_a7220ac9c5c343f5988a17a59dd65f0e","IPY_MODEL_1a3d37cf554d43a984fb51b62814f319"],"layout":"IPY_MODEL_7bf8f692f82449e0bdef281660652b79"}},"ac67751ea5f04c86a6f8585fbc415ec9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07db7c695785407ba13e453da92b2bba","placeholder":"​","style":"IPY_MODEL_246d9a5a461a4bbba393ba7be65eb22d","value":"Downloading builder script: 100%"}},"a7220ac9c5c343f5988a17a59dd65f0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84d5f99eb2a04aa497f1380beb453843","max":6270,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27ba4e7d187f4d7aa5afb67647e655cf","value":6270}},"1a3d37cf554d43a984fb51b62814f319":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2788b8d5d6b3482aa421b572d85085b6","placeholder":"​","style":"IPY_MODEL_389332d2d10a4ee1aefb1a1d683a6389","value":" 6.27k/6.27k [00:00&lt;00:00, 358kB/s]"}},"7bf8f692f82449e0bdef281660652b79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07db7c695785407ba13e453da92b2bba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"246d9a5a461a4bbba393ba7be65eb22d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84d5f99eb2a04aa497f1380beb453843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27ba4e7d187f4d7aa5afb67647e655cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2788b8d5d6b3482aa421b572d85085b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"389332d2d10a4ee1aefb1a1d683a6389":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8468831,"sourceType":"datasetVersion","datasetId":5049496},{"sourceId":8475532,"sourceType":"datasetVersion","datasetId":5054413}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{"id":"dVJKr-2PWGQ-"}},{"cell_type":"code","source":"!pip install transformers[torch] datasets sentencepiece sacrebleu evaluate rouge_score -U\n\nimport torch\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, EarlyStoppingCallback, get_linear_schedule_with_warmup, AdamW, BartTokenizer, BartForConditionalGeneration\nfrom datasets import load_dataset, load_metric\nimport evaluate\nimport numpy as np\nimport pandas as pd\nimport zipfile\nimport requests\nimport os","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvvdPZkT8LrX","outputId":"f6be9a5e-dd52-4529-fcc8-2bb877be8d91","execution":{"iopub.status.busy":"2024-05-21T11:56:55.686146Z","iopub.execute_input":"2024-05-21T11:56:55.687018Z","iopub.status.idle":"2024-05-21T11:57:43.990752Z","shell.execute_reply.started":"2024-05-21T11:56:55.686974Z","shell.execute_reply":"2024-05-21T11:57:43.989897Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nCollecting datasets\n  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nCollecting transformers[torch]\n  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nCollecting huggingface-hub<1.0,>=0.23.0 (from transformers[torch])\n  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nCollecting tokenizers<0.20,>=0.19 (from transformers[torch])\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.29.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nDownloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=941485d71a0a13f1b58819419de76f38730e7f8e826daa98f49a599797234b0e\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: portalocker, sacrebleu, rouge_score, huggingface-hub, tokenizers, transformers, datasets, evaluate\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.22.2\n    Uninstalling huggingface-hub-0.22.2:\n      Successfully uninstalled huggingface-hub-0.22.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.39.3\n    Uninstalling transformers-4.39.3:\n      Successfully uninstalled transformers-4.39.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.18.0\n    Uninstalling datasets-2.18.0:\n      Successfully uninstalled datasets-2.18.0\nSuccessfully installed datasets-2.19.1 evaluate-0.4.2 huggingface-hub-0.23.0 portalocker-2.8.2 rouge_score-0.1.2 sacrebleu-2.4.2 tokenizers-0.19.1 transformers-4.41.0\n","output_type":"stream"},{"name":"stderr","text":"2024-05-21 11:57:32.878510: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-21 11:57:32.878640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-21 11:57:33.017919: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# verify that packages are install correctly","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nimport datasets\nimport sentencepiece\nimport sacrebleu\nimport evaluate\n\nprint(f\"transformers version: {transformers.__version__}\")\nprint(f\"datasets version: {datasets.__version__}\")\nprint(f\"sentencepiece version: {sentencepiece.__version__}\")\nprint(f\"sacrebleu version: {sacrebleu.__version__}\")\nprint(f\"evaluate version: {evaluate.__version__}\")\nprint(\"CUDA available:\", torch.cuda.is_available())","metadata":{"id":"gk97_DdI8QEa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"02397177-8fdf-4413-b39a-adb96f8236ef","execution":{"iopub.status.busy":"2024-05-21T11:57:43.992259Z","iopub.execute_input":"2024-05-21T11:57:43.992819Z","iopub.status.idle":"2024-05-21T11:57:44.090676Z","shell.execute_reply.started":"2024-05-21T11:57:43.992794Z","shell.execute_reply":"2024-05-21T11:57:44.089734Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"transformers version: 4.41.0\ndatasets version: 2.19.1\nsentencepiece version: 0.2.0\nsacrebleu version: 2.4.2\nevaluate version: 0.4.2\nCUDA available: True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load the dataset ","metadata":{}},{"cell_type":"code","source":"# List of CSV files to load\ncsv_files = [\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/wikipedia.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/assorted_government.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/generated_reviews_crowd.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/generated_reviews_translator.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/generated_reviews_yn.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/mozilla_common_voice.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/msr_paraphrase.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/nus_sms.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/paracrawl.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/task_master_1.csv',\n    '/kaggle/input/scb-mt-en-th-2020/scb-mt-en-th-2020/thai_websites.csv'\n]\n\n# Load the CSV files\ndataframes = [pd.read_csv(file) for file in csv_files]\ndata_df = pd.concat(dataframes, ignore_index=True)\n\n# Rename columns \ndata_df = data_df.rename(columns={'en_text': 'source_text', 'th_text': 'target_text'})\n\n# Check the size of the dataset\nprint(f\"Total number of examples: {len(data_df)}\")","metadata":{"id":"-8-Rtwi7WYjU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00617c7a-660c-4172-f9ac-1c34735c8e8c","execution":{"iopub.status.busy":"2024-05-21T15:42:45.690521Z","iopub.execute_input":"2024-05-21T15:42:45.690906Z","iopub.status.idle":"2024-05-21T15:43:07.247841Z","shell.execute_reply.started":"2024-05-21T15:42:45.690877Z","shell.execute_reply":"2024-05-21T15:43:07.246781Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Total number of examples: 988249\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use only a subset of the dataset for training to reduce time\nsubset_fraction = 0.12  # Use 12% of the dataset\ndata_df = data_df.sample(frac=subset_fraction, random_state=42) \n\n# Split the dataset into train and test sets\ntrain_df = data_df.sample(frac=0.8, random_state=42)\ntest_df = data_df.drop(train_df.index)\n","metadata":{"id":"zfHhFe9Mdvfu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5752c06b-297b-4fd8-94d0-8346a291fbe8","execution":{"iopub.status.busy":"2024-05-21T15:43:10.334224Z","iopub.execute_input":"2024-05-21T15:43:10.335121Z","iopub.status.idle":"2024-05-21T15:43:10.448705Z","shell.execute_reply.started":"2024-05-21T15:43:10.335082Z","shell.execute_reply":"2024-05-21T15:43:10.447675Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Balance the dataset by duplicating and reversing sentence pairs\ntrain_en_th = train_df.sample(frac=0.5, random_state=42)\ntrain_th_en = train_en_th.rename(columns={'source_text': 'target_text', 'target_text': 'source_text'})\ntrain_balanced_df = pd.concat([train_en_th, train_th_en], axis=0)\n\n# Convert DataFrame to Dataset\ntrain_dataset = Dataset.from_pandas(train_balanced_df)\n\n# Use only a smaller subset of the test dataset\ntest_df = test_df.sample(frac=0.1, random_state=42)  # Use 10% of the test dataset\ntest_dataset = Dataset.from_pandas(test_df)\n\n\n# Verify sizes after splitting\nprint(f\"Number of training examples: {len(train_balanced_df)}\")\nprint(f\"Number of test examples: {len(test_df)}\")\n\n","metadata":{"id":"siMvi8x_cexk","colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["25e99a4b316349319ec7506ea6abaaf5","9ad046f44bee4ff680a74ad7c9b02028","13138fd7a2bb4f3684de3a7d4bdcbfde","af84931c4d884942abbb008b26aebfe4","8190bb00cfbc4fd1b1b4f48dada09de1","da23d5286d1c4dda96aafc71f3784a08","21ff29380b0543c0a952a0d0cbd25735","59e6803bb4474adeaa9e92ade7225c49","b275fbd860d04bdd80201780f9cbf3b8","4c528b2ff0be4ad89fd717f663207add","9830b85dc4644e329b1f33c3e5ed1927","1e8d9a8dfd2b4930b1b3f65d1267700a","a5461b1ebcf2424094c1bd962d2561e4","185a3de6c95c4b2eb6135aee70d0d53e","76afd9ccebaa4892bfbd1a3c1b9a18ca","e3edede5e76e4d3e82ae3db7a3d8292a","9690b14bb286488aa62500a58829cc6f","66ed6cef9aa34e3f952fdf6c093c8ee9","1b75ae07773d4833a19de3eee137475b","49947fee612d4d9f83fa9d2fe4db5d73","603fc97e729a4e47bb89e48a8f35dc55","1d205fcf02444055a0712760fb25df36","580f362b972e4ac7962e25978184991d","9a42ff6c11c24975a9637c57598736cc","d73332e32b254ec990711cff39bbc2e8","e8a3dc345f9e4b1c85de8d8015a61aec","4da552dab3064bda9ea998af4ce20663","d2b7088f15be42629eb066fe445e08e2","3418e940578d416ab0f567fc452c422e","aaae1fbaa35d4e579764a2a5b30e608e","6c04e66b257b49eaad330f0ba0667eb3","f1c5acba14304426a82ccf6e4620fa27","8f877290acff4305a0b50df4dc32050c","fdae1c46ff884f39a7bc2de251113ce1","6e56068256aa40b08fa9d98b5cbd528b","af7ae84e373845b9845513c0e644b6a2","f729054d9b5140aabd696558f90f32dc","a89acce6a579432eb969cf599a133083","3d66eea3965c422190245d87dd12208d","55d1c71063c748b08c3939647548e555","a3cdcd110e5947e692ad24748a544f81","960e94d4513b4ba2a1e02463236b391b","ebdd8c3b8585461cb7fc343fad89b40a","5e852771bf024007ae3b9836fbaf7fa7"]},"outputId":"5cad03a6-75c4-42a8-da43-9dfa4ade4559","execution":{"iopub.status.busy":"2024-05-21T15:43:15.297247Z","iopub.execute_input":"2024-05-21T15:43:15.297872Z","iopub.status.idle":"2024-05-21T15:43:15.620729Z","shell.execute_reply.started":"2024-05-21T15:43:15.297842Z","shell.execute_reply":"2024-05-21T15:43:15.619724Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Number of training examples: 94872\nNumber of test examples: 2372\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pre-trained tokenizer and model\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\nmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n\n# Tokenization function\ndef tokenize_function(examples):\n    source = examples['source_text']\n    target = examples['target_text']\n    model_inputs = tokenizer(source, max_length=64, truncation=True, padding='max_length')\n    labels = tokenizer(text_target=target, max_length=64, truncation=True, padding='max_length')\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Tokenize datasets\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\ntrain_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntest_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n\n\n# Verify the number of examples after tokenization\nprint(f\"Number of tokenized training examples: {len(train_dataset)}\")\nprint(f\"Number of tokenized test examples: {len(test_dataset)}\")\n","metadata":{"id":"0MvEDFqyWbcH","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["e6553531097640e9a30ef4a544a28bb7","009d1195d2df481dba00cc791d66db8a","a2fb856bc9b043b4a90db214828eb13f","40d050d991d345d39cfd8f4431dbf1a2","fa77e8a107e24d848c734bd99014ecac","2f2cbe4a49c644d6affdd17e613a9449","4aaa81ec184a42339ff634c266e60508","480b62486716452b9ae7f9f031fdf0bc","6548e32998f9418f84a3ac02c6d69fda","54a571e996a740b4be206fecaeedbc19","6af948a861d74a60a94c8d0fbf0fba9d","acb2af4ae2af4015a76edef27ce358d0","c699cf7cbed549be9bc1cfe174873c71","033be642a89a4049930df32478685386","1161eb65e8d14291bac3d0699c11956a","a2a17afd637f4519a1245da858c2ff1e","f96ef6c55a734747ba857179ca96150e","033cb27e8ac0489fbe50603c663f6775","b7dfb7ee827b4db0a3b34bedd238b47b","454a3f67a7be4768bc39619f47fe141b","d116751f6ce3443482dfca365e25ea49","17024d77846c4c4aa66d45cf4e92a605","53a5274736214470b8d55843b6df30c9","f4167910f6a0410195a65d2256f026c7","ac1c806fd19143ddae09f94dee64fb3e","3ea5cf8babee4d88b69a220a85a0b517","2e8ce0e1d2244f3ab074f4c11280f06c","f6662340c6ad492eba572cf413cbac6f","862b4e4c715744be811f753edf8cce57","f533e91132ae479b83fe606476761214","dce1c8bb4fcd40d8ac480df0636ae04f","eb7ddf006e2d4f48982567e31d7ec36c","304c4f2814a843c9bd4b8c03704d84ea"]},"outputId":"14cf0f21-6a69-4688-8633-1d77004faa45","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,  # Reduce number of epochs\n    per_device_train_batch_size=1,  # Reduce batch size\n    per_device_eval_batch_size=1,  # Reduce batch size\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100,\n    evaluation_strategy=\"steps\",\n    save_steps=1000,\n    eval_steps=1000,\n    learning_rate=5e-5,\n    predict_with_generate=True,\n    gradient_accumulation_steps=16,  # Increase gradient accumulation\n    fp16=True if torch.cuda.is_available() else False,\n    save_total_limit=3,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"bleu\",\n    greater_is_better=True\n)\n\n# Define evaluation metrics\nmetric_bleu = evaluate.load('sacrebleu')\nmetric_rouge = evaluate.load('rouge')\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    decoded_preds = [pred.replace(\"\\n\", \" \") for pred in decoded_preds]\n    decoded_labels = [label.replace(\"\\n\", \" \") for label in decoded_labels]\n    decoded_labels = [[label] for label in decoded_labels]\n    bleu_result = metric_bleu.compute(predictions=decoded_preds, references=decoded_labels)\n    rouge_result = metric_rouge.compute(predictions=decoded_preds, references=decoded_labels)\n    rouge1_fmeasure = rouge_result['rouge1']\n    rouge2_fmeasure = rouge_result['rouge2']\n    rougeL_fmeasure = rouge_result['rougeL']\n    result = {\n        \"bleu\": bleu_result[\"score\"],\n        \"rouge1\": rouge1_fmeasure,\n        \"rouge2\": rouge2_fmeasure,\n        \"rougeL\": rougeL_fmeasure,\n    }\n    return result\n","metadata":{"id":"EhzasRG_GIma","colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["2dfe2255fac34b14acf94e76716ef7b8","5a0eba8df5134824a502adb518712068","c8463a53af7c45cc947a6409dc319351","b5ec44d3e88d4da5873d835b7448d9b4","d16acbb318884408b13a4a2cae690d87","4447ea033ba441ceac1bbd940a9c4eac","4d23e6c83b07471f9d102704cd30b20e","a6df32c558a94f7b86758089f0e54ad3","94a405ee13b44e1fae258adfc5469dc4","7f67bd85bcc345bfbd2771ca2feef0e2","ba459dce3a464746a3644169826a47f1","dd92bd7a26fb4a629675880ae163b745","ac67751ea5f04c86a6f8585fbc415ec9","a7220ac9c5c343f5988a17a59dd65f0e","1a3d37cf554d43a984fb51b62814f319","7bf8f692f82449e0bdef281660652b79","07db7c695785407ba13e453da92b2bba","246d9a5a461a4bbba393ba7be65eb22d","84d5f99eb2a04aa497f1380beb453843","27ba4e7d187f4d7aa5afb67647e655cf","2788b8d5d6b3482aa421b572d85085b6","389332d2d10a4ee1aefb1a1d683a6389"]},"outputId":"d5f3442a-8516-46d3-f8ae-390fc1e3e977","execution":{"iopub.status.busy":"2024-05-21T01:48:41.146503Z","iopub.execute_input":"2024-05-21T01:48:41.146867Z","iopub.status.idle":"2024-05-21T01:48:42.300591Z","shell.execute_reply.started":"2024-05-21T01:48:41.146838Z","shell.execute_reply":"2024-05-21T01:48:42.299817Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize the trainer with early stopping\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Increase patience\n)\n\n# Train the model\ntrainer.train()","metadata":{"id":"myETydVrGK8A","colab":{"base_uri":"https://localhost:8080/","height":75},"outputId":"985f4fe7-32f2-442e-f59b-23c96613ad9c","execution":{"iopub.status.busy":"2024-05-21T01:48:50.715261Z","iopub.execute_input":"2024-05-21T01:48:50.715629Z","iopub.status.idle":"2024-05-21T06:00:47.979785Z","shell.execute_reply.started":"2024-05-21T01:48:50.715601Z","shell.execute_reply":"2024-05-21T06:00:47.978967Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5929' max='5929' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5929/5929 4:11:55, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>1.322400</td>\n      <td>1.062462</td>\n      <td>6.470108</td>\n      <td>0.026844</td>\n      <td>0.014404</td>\n      <td>0.026401</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.148500</td>\n      <td>0.881074</td>\n      <td>6.751840</td>\n      <td>0.033744</td>\n      <td>0.016658</td>\n      <td>0.033401</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.055700</td>\n      <td>0.766987</td>\n      <td>9.012571</td>\n      <td>0.033445</td>\n      <td>0.014595</td>\n      <td>0.033081</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.989300</td>\n      <td>0.709166</td>\n      <td>10.573017</td>\n      <td>0.043552</td>\n      <td>0.018963</td>\n      <td>0.043167</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.974500</td>\n      <td>0.663262</td>\n      <td>10.775226</td>\n      <td>0.044642</td>\n      <td>0.017878</td>\n      <td>0.044312</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5929, training_loss=1.2391288993450698, metrics={'train_runtime': 15116.8448, 'train_samples_per_second': 6.276, 'train_steps_per_second': 0.392, 'total_flos': 1.2848763185922048e+16, 'train_loss': 1.2391288993450698, 'epoch': 0.9999156758579981})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model\neval_results = trainer.evaluate()\nprint(eval_results)\n\n# Save the model\nmodel.save_pretrained('./eng-tha-translation-model')\ntokenizer.save_pretrained('./eng-tha-translation-model')","metadata":{"id":"8NpwGPrvDtOr","execution":{"iopub.status.busy":"2024-05-21T06:22:44.337223Z","iopub.execute_input":"2024-05-21T06:22:44.338131Z","iopub.status.idle":"2024-05-21T06:38:34.632924Z","shell.execute_reply.started":"2024-05-21T06:22:44.338096Z","shell.execute_reply":"2024-05-21T06:38:34.632044Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2372' max='2372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2372/2372 15:37]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"name":"stdout","text":"{'eval_loss': 0.6632624268531799, 'eval_bleu': 10.775226257004267, 'eval_rouge1': 0.044642346309467645, 'eval_rouge2': 0.017877552932359, 'eval_rougeL': 0.04431212428248934, 'eval_runtime': 947.7877, 'eval_samples_per_second': 2.503, 'eval_steps_per_second': 2.503, 'epoch': 0.9999156758579981}\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"('./eng-tha-translation-model/tokenizer_config.json',\n './eng-tha-translation-model/special_tokens_map.json',\n './eng-tha-translation-model/vocab.json',\n './eng-tha-translation-model/merges.txt',\n './eng-tha-translation-model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"**end train1**","metadata":{}},{"cell_type":"markdown","source":"# Translation function","metadata":{}},{"cell_type":"code","source":"def translate(text, source_lang='en', target_lang='th'):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Tokenize the input text\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True, padding='max_length')\n    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the same device as the model\n    \n    model.to(device)  # Move model to the correct device\n    \n    # Generate translation\n    outputs = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=128)\n    \n    # Decode the generated outputs\n    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return translated_text\n\ndef test_translation():\n    direction = input(\"Enter translation direction (1 for EN-TH, 2 for TH-EN): \")\n    text = input(\"Enter the text to translate: \")\n    if direction == '1':\n        translated_text = translate(text, source_lang='en', target_lang='th')\n    else:\n        translated_text = translate(text, source_lang='th', target_lang='en')\n    print(f\"Translated text: {translated_text}\")\n\n","metadata":{"id":"9aWPJ9CTOEEr","execution":{"iopub.status.busy":"2024-05-21T12:03:59.863534Z","iopub.execute_input":"2024-05-21T12:03:59.864188Z","iopub.status.idle":"2024-05-21T12:03:59.872788Z","shell.execute_reply.started":"2024-05-21T12:03:59.864156Z","shell.execute_reply":"2024-05-21T12:03:59.871424Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"train2 start and load model1 from zip with new data set","metadata":{}},{"cell_type":"code","source":"# Load all CSV files\ndfs = [pd.read_csv(file) for file in csv_files]\ndata_df = pd.concat(dfs, axis=0)\n\n# Use a smaller subset of the dataset for training\nsubset_fraction = 0.11  # Use 11% of the dataset for faster training\ndata_df = data_df.sample(frac=subset_fraction, random_state=50)\n\n# Split the dataset into train and test sets\ntrain_df = data_df.sample(frac=0.8, random_state=50) #80 percent of data set\ntest_df = data_df.drop(train_df.index) #20 percent of data set\n\n# Use only a smaller subset of the test dataset\ntest_df = test_df.sample(frac=0.2, random_state=50)  # 20% of the test dataset\ntest_dataset = Dataset.from_pandas(test_df)\n\n# Balance the dataset by duplicating and reversing sentence pairs\ntrain_en_th = train_df.sample(frac=0.8, random_state=50)\ntrain_th_en = train_en_th.rename(columns={'en_text': 'th_text', 'th_text': 'en_text'})\ntrain_balanced_df = pd.concat([train_en_th, train_th_en], axis=0)\n\n# Convert DataFrame to Dataset\ntrain_dataset = Dataset.from_pandas(train_balanced_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:13:10.843789Z","iopub.execute_input":"2024-05-21T12:13:10.844144Z","iopub.status.idle":"2024-05-21T12:13:18.954275Z","shell.execute_reply.started":"2024-05-21T12:13:10.844116Z","shell.execute_reply":"2024-05-21T12:13:18.953490Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Verify sizes after splitting\nprint(f\"Number of training examples: {len(train_balanced_df)}\")\nprint(f\"Number of test examples: {len(test_df)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:13:24.680944Z","iopub.execute_input":"2024-05-21T12:13:24.681335Z","iopub.status.idle":"2024-05-21T12:13:24.687058Z","shell.execute_reply.started":"2024-05-21T12:13:24.681305Z","shell.execute_reply":"2024-05-21T12:13:24.685976Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of training examples: 139146\nNumber of test examples: 2981\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the pre-trained tokenizer and model from the first model\nmodel_path = '/kaggle/input/model1/eng-tha-translation-model'\ntokenizer = BartTokenizer.from_pretrained(model_path)\nmodel = BartForConditionalGeneration.from_pretrained(model_path)\n\n# Tokenization function\ndef tokenize_function(examples):\n    source = examples['en_text']\n    target = examples['th_text']\n    model_inputs = tokenizer(source, max_length=64, truncation=True, padding='max_length')\n    labels = tokenizer(text_target=target, max_length=64, truncation=True, padding='max_length')\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:13:31.779968Z","iopub.execute_input":"2024-05-21T12:13:31.780845Z","iopub.status.idle":"2024-05-21T12:13:33.169566Z","shell.execute_reply.started":"2024-05-21T12:13:31.780812Z","shell.execute_reply":"2024-05-21T12:13:33.168770Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Tokenize the datasets\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\n\ntrain_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntest_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:13:41.643086Z","iopub.execute_input":"2024-05-21T12:13:41.643495Z","iopub.status.idle":"2024-05-21T12:16:18.736633Z","shell.execute_reply.started":"2024-05-21T12:13:41.643465Z","shell.execute_reply":"2024-05-21T12:16:18.735770Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/139146 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e903107008274e82b9ec9db4971c4904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2981 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1be0b34f5bfa448bbb612ce80be70f5c"}},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Number of tokenized training examples: {len(train_dataset)}\")\nprint(f\"Number of tokenized test examples: {len(test_dataset)}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:16:20.666278Z","iopub.execute_input":"2024-05-21T12:16:20.666667Z","iopub.status.idle":"2024-05-21T12:16:20.671830Z","shell.execute_reply.started":"2024-05-21T12:16:20.666639Z","shell.execute_reply":"2024-05-21T12:16:20.670980Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Number of tokenized training examples: 139146\nNumber of tokenized test examples: 2981\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    decoded_preds = [pred.replace(\"\\n\", \" \") for pred in decoded_preds]\n    decoded_labels = [label.replace(\"\\n\", \" \") for label in decoded_labels]\n    decoded_labels = [[label] for label in decoded_labels]\n    bleu_result = metric_bleu.compute(predictions=decoded_preds, references=decoded_labels)\n    rouge_result = metric_rouge.compute(predictions=decoded_preds, references=decoded_labels)\n    rouge1_fmeasure = rouge_result['rouge1']\n    rouge2_fmeasure = rouge_result['rouge2']\n    rougeL_fmeasure = rouge_result['rougeL']\n    result = {\n        \"bleu\": bleu_result[\"score\"],\n        \"rouge1\": rouge1_fmeasure,\n        \"rouge2\": rouge2_fmeasure,\n        \"rougeL\": rougeL_fmeasure,\n    }\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:16:44.438348Z","iopub.execute_input":"2024-05-21T12:16:44.439048Z","iopub.status.idle":"2024-05-21T12:16:44.446303Z","shell.execute_reply.started":"2024-05-21T12:16:44.439019Z","shell.execute_reply":"2024-05-21T12:16:44.445326Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,  \n    per_device_train_batch_size=8,  \n    per_device_eval_batch_size=8,  \n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=1000,  \n    evaluation_strategy=\"steps\",\n    save_steps=2000,  \n    eval_steps=2000,  \n    learning_rate=5e-5,  \n    predict_with_generate=True,\n    gradient_accumulation_steps=8,  # gradient accumulation \n    fp16=True if torch.cuda.is_available() else False,\n    save_total_limit=3,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"bleu\",\n    greater_is_better=True\n)\n\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:18:14.414193Z","iopub.execute_input":"2024-05-21T12:18:14.415121Z","iopub.status.idle":"2024-05-21T12:18:14.461361Z","shell.execute_reply.started":"2024-05-21T12:18:14.415085Z","shell.execute_reply":"2024-05-21T12:18:14.460337Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the second model  after second train\ntrainer.save_model('./eng-tha-translation-second-model')\ntokenizer.save_pretrained('./eng-tha-translation-second-model')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:49:06.091894Z","iopub.execute_input":"2024-05-21T13:49:06.092279Z","iopub.status.idle":"2024-05-21T13:49:08.262100Z","shell.execute_reply.started":"2024-05-21T13:49:06.092249Z","shell.execute_reply":"2024-05-21T13:49:08.261146Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"('./eng-tha-translation-second-model/tokenizer_config.json',\n './eng-tha-translation-second-model/special_tokens_map.json',\n './eng-tha-translation-second-model/vocab.json',\n './eng-tha-translation-second-model/merges.txt',\n './eng-tha-translation-second-model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"# result after second train","metadata":{}},{"cell_type":"code","source":"test_translation()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:50:06.697265Z","iopub.execute_input":"2024-05-21T13:50:06.698209Z","iopub.status.idle":"2024-05-21T13:50:16.900604Z","shell.execute_reply.started":"2024-05-21T13:50:06.698167Z","shell.execute_reply":"2024-05-21T13:50:16.899646Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  1\nEnter the text to translate:  กินข้าว\n"},{"name":"stdout","text":"Translated text: Very disappointing.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# third train with new random data set","metadata":{}},{"cell_type":"code","source":"dfs = [pd.read_csv(file) for file in csv_files]\ndata_df = pd.concat(dfs, axis=0)\n\n\nsubset_fraction = 0.05  \ndata_df = data_df.sample(frac=subset_fraction, random_state=50)\n\n\ntrain_df = data_df.sample(frac=0.8, random_state=25) #80 percent of data set\ntest_df = data_df.drop(train_df.index) #20 percent of data set\n\n\ntest_df = test_df.sample(frac=0.2, random_state=25)  # Use 10% of the test dataset\ntest_dataset = Dataset.from_pandas(test_df)\n\n\ntrain_en_th = train_df.sample(frac=0.8, random_state=25)\ntrain_th_en = train_en_th.rename(columns={'en_text': 'th_text', 'th_text': 'en_text'})\ntrain_balanced_df = pd.concat([train_en_th, train_th_en], axis=0)\n\n\ntrain_dataset = Dataset.from_pandas(train_balanced_df)\ntest_dataset = Dataset.from_pandas(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:57:39.315113Z","iopub.execute_input":"2024-05-21T13:57:39.316016Z","iopub.status.idle":"2024-05-21T13:57:47.070843Z","shell.execute_reply.started":"2024-05-21T13:57:39.315981Z","shell.execute_reply":"2024-05-21T13:57:47.070064Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of training examples: {len(train_balanced_df)}\")\nprint(f\"Number of test examples: {len(test_df)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:58:10.094021Z","iopub.execute_input":"2024-05-21T13:58:10.094419Z","iopub.status.idle":"2024-05-21T13:58:10.099835Z","shell.execute_reply.started":"2024-05-21T13:58:10.094367Z","shell.execute_reply":"2024-05-21T13:58:10.098947Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Number of training examples: 63248\nNumber of test examples: 1662\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\ntrain_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntest_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric_bleu = evaluate.load('sacrebleu')\nmetric_rouge = evaluate.load('rouge')\n\ntokenizer = BartTokenizer.from_pretrained('./eng-tha-translation-second-model')\nmodel = BartForConditionalGeneration.from_pretrained('./eng-tha-translation-second-model')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training arguments for further training\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,  \n    per_device_train_batch_size=8,  \n    per_device_eval_batch_size=8,  \n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=1000, \n    evaluation_strategy=\"steps\",\n    save_steps=500, \n    eval_steps=500, \n    learning_rate=1e-4,  \n    predict_with_generate=True,\n    gradient_accumulation_steps=8,\n    fp16=True if torch.cuda.is_available() else False,\n    save_total_limit=3,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"bleu\",\n    greater_is_better=True\n)\n\n# Initialize the trainer with early stopping\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Reduce patience for quicker stopping\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:08:03.755383Z","iopub.execute_input":"2024-05-21T14:08:03.756254Z","iopub.status.idle":"2024-05-21T14:08:03.795649Z","shell.execute_reply.started":"2024-05-21T14:08:03.756221Z","shell.execute_reply":"2024-05-21T14:08:03.794710Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:08:07.217282Z","iopub.execute_input":"2024-05-21T14:08:07.218130Z","iopub.status.idle":"2024-05-21T14:46:59.074614Z","shell.execute_reply.started":"2024-05-21T14:08:07.218100Z","shell.execute_reply":"2024-05-21T14:46:59.073690Z"},"trusted":true},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='988' max='988' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [988/988 38:48, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>No log</td>\n      <td>0.546934</td>\n      <td>10.175849</td>\n      <td>0.038889</td>\n      <td>0.010396</td>\n      <td>0.037620</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=988, training_loss=0.8553760235126202, metrics={'train_runtime': 2331.1065, 'train_samples_per_second': 27.132, 'train_steps_per_second': 0.424, 'total_flos': 8564397387546624.0, 'train_loss': 0.8553760235126202, 'epoch': 0.9997470275739945})"},"metadata":{}}]},{"cell_type":"code","source":"# save the third trained model \ntrainer.save_model('./eng-tha-translation-third-model')\ntokenizer.save_pretrained('./eng-tha-translation-third-model')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:47:01.462337Z","iopub.execute_input":"2024-05-21T14:47:01.463083Z","iopub.status.idle":"2024-05-21T14:47:03.623376Z","shell.execute_reply.started":"2024-05-21T14:47:01.463045Z","shell.execute_reply":"2024-05-21T14:47:03.622421Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"('./eng-tha-translation-third-model/tokenizer_config.json',\n './eng-tha-translation-third-model/special_tokens_map.json',\n './eng-tha-translation-third-model/vocab.json',\n './eng-tha-translation-third-model/merges.txt',\n './eng-tha-translation-third-model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"#zip the second model and create download link\n!zip -r ./eng-tha-translation-second-model.zip ./eng-tha-translation-second-model\n\nfrom IPython.display import FileLink\nFileLink(r'eng-tha-translation-second-model.zip')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:00:43.808801Z","iopub.execute_input":"2024-05-21T14:00:43.809170Z","iopub.status.idle":"2024-05-21T14:02:13.977412Z","shell.execute_reply.started":"2024-05-21T14:00:43.809142Z","shell.execute_reply":"2024-05-21T14:02:13.976432Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"  adding: eng-tha-translation-second-model/ (stored 0%)\n  adding: eng-tha-translation-second-model/special_tokens_map.json (deflated 85%)\n  adding: eng-tha-translation-second-model/generation_config.json (deflated 45%)\n  adding: eng-tha-translation-second-model/training_args.bin (deflated 51%)\n  adding: eng-tha-translation-second-model/model.safetensors (deflated 7%)\n  adding: eng-tha-translation-second-model/tokenizer_config.json (deflated 76%)\n  adding: eng-tha-translation-second-model/vocab.json (deflated 68%)\n  adding: eng-tha-translation-second-model/config.json (deflated 63%)\n  adding: eng-tha-translation-second-model/merges.txt (deflated 53%)\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/eng-tha-translation-second-model.zip","text/html":"<a href='eng-tha-translation-second-model.zip' target='_blank'>eng-tha-translation-second-model.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"#zip the third model\n!zip -r ./eng-tha-translation-third-model.zip ./eng-tha-translation-third-model\n\nfrom IPython.display import FileLink\nFileLink(r'eng-tha-translation-third-model.zip')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:47:24.881287Z","iopub.execute_input":"2024-05-21T14:47:24.881687Z","iopub.status.idle":"2024-05-21T14:48:50.307382Z","shell.execute_reply.started":"2024-05-21T14:47:24.881658Z","shell.execute_reply":"2024-05-21T14:48:50.306223Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"  adding: eng-tha-translation-third-model/ (stored 0%)\n  adding: eng-tha-translation-third-model/special_tokens_map.json (deflated 85%)\n  adding: eng-tha-translation-third-model/generation_config.json (deflated 45%)\n  adding: eng-tha-translation-third-model/training_args.bin (deflated 51%)\n  adding: eng-tha-translation-third-model/model.safetensors (deflated 7%)\n  adding: eng-tha-translation-third-model/tokenizer_config.json (deflated 76%)\n  adding: eng-tha-translation-third-model/vocab.json (deflated 68%)\n  adding: eng-tha-translation-third-model/config.json (deflated 63%)\n  adding: eng-tha-translation-third-model/merges.txt (deflated 53%)\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/eng-tha-translation-third-model.zip","text/html":"<a href='eng-tha-translation-third-model.zip' target='_blank'>eng-tha-translation-third-model.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# translation after thrid train","metadata":{}},{"cell_type":"code","source":"test_translation()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:53:33.934886Z","iopub.execute_input":"2024-05-21T14:53:33.935276Z","iopub.status.idle":"2024-05-21T14:53:50.924250Z","shell.execute_reply.started":"2024-05-21T14:53:33.935241Z","shell.execute_reply":"2024-05-21T14:53:50.923336Z"},"trusted":true},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  2\nEnter the text to translate:  ฉันชอบรถ\n"},{"name":"stdout","text":"Translated text: I love the car.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# fourth train","metadata":{}},{"cell_type":"code","source":"dfs = [pd.read_csv(file) for file in csv_files]\ndata_df = pd.concat(dfs, axis=0)\n\n\nsubset_fraction = 0.05  #5 percent\ndata_df = data_df.sample(frac=subset_fraction, random_state=80)\n\n\ntrain_df = data_df.sample(frac=0.8, random_state=80) #80 percent of data set\ntest_df = data_df.drop(train_df.index) #20 percent of data set\n\n\ntest_df = test_df.sample(frac=0.2, random_state=80)  # Use 10% of the test dataset\ntest_dataset = Dataset.from_pandas(test_df)\n\n\ntrain_en_th = train_df.sample(frac=0.8, random_state=80)\ntrain_th_en = train_en_th.rename(columns={'en_text': 'th_text', 'th_text': 'en_text'})\ntrain_balanced_df = pd.concat([train_en_th, train_th_en], axis=0)\n\n\ntrain_dataset = Dataset.from_pandas(train_balanced_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\ntrain_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntest_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:57:25.605663Z","iopub.execute_input":"2024-05-21T14:57:25.606060Z","iopub.status.idle":"2024-05-21T14:58:55.946338Z","shell.execute_reply.started":"2024-05-21T14:57:25.606033Z","shell.execute_reply":"2024-05-21T14:58:55.945508Z"},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/63248 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be7132175e340d589c039f38d3bae58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1646 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5de02311e7d74a0ab90d32d4b52485c9"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BartTokenizer.from_pretrained('./eng-tha-translation-third-model')\nmodel = BartForConditionalGeneration.from_pretrained('./eng-tha-translation-third-model')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:59:30.754680Z","iopub.execute_input":"2024-05-21T14:59:30.755526Z","iopub.status.idle":"2024-05-21T14:59:32.389840Z","shell.execute_reply.started":"2024-05-21T14:59:30.755490Z","shell.execute_reply":"2024-05-21T14:59:32.388931Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,  \n    per_device_train_batch_size=8,  \n    per_device_eval_batch_size=8,  \n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=1000, \n    evaluation_strategy=\"steps\",\n    save_steps=500, \n    eval_steps=500, \n    learning_rate=1e-4,  \n    predict_with_generate=True,\n    gradient_accumulation_steps=8,\n    fp16=True if torch.cuda.is_available() else False,\n    save_total_limit=3,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"bleu\",\n    greater_is_better=True\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  \n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:59:33.825267Z","iopub.execute_input":"2024-05-21T14:59:33.825662Z","iopub.status.idle":"2024-05-21T14:59:34.247825Z","shell.execute_reply.started":"2024-05-21T14:59:33.825634Z","shell.execute_reply":"2024-05-21T14:59:34.247027Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:59:36.763741Z","iopub.execute_input":"2024-05-21T14:59:36.764097Z","iopub.status.idle":"2024-05-21T15:38:46.054580Z","shell.execute_reply.started":"2024-05-21T14:59:36.764072Z","shell.execute_reply":"2024-05-21T15:38:46.053598Z"},"trusted":true},"execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='988' max='988' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [988/988 39:06, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>No log</td>\n      <td>0.510781</td>\n      <td>10.624615</td>\n      <td>0.031829</td>\n      <td>0.011363</td>\n      <td>0.031941</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=988, training_loss=0.8604749301184527, metrics={'train_runtime': 2348.6722, 'train_samples_per_second': 26.929, 'train_steps_per_second': 0.421, 'total_flos': 8564397387546624.0, 'train_loss': 0.8604749301184527, 'epoch': 0.9997470275739945})"},"metadata":{}}]},{"cell_type":"code","source":"# save the third trained model \ntrainer.save_model('./eng-tha-translation-fourth-model')\ntokenizer.save_pretrained('./eng-tha-translation-fourth-model')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:38:49.549804Z","iopub.execute_input":"2024-05-21T15:38:49.550463Z","iopub.status.idle":"2024-05-21T15:38:51.821217Z","shell.execute_reply.started":"2024-05-21T15:38:49.550430Z","shell.execute_reply":"2024-05-21T15:38:51.820284Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"('./eng-tha-translation-fourth-model/tokenizer_config.json',\n './eng-tha-translation-fourth-model/special_tokens_map.json',\n './eng-tha-translation-fourth-model/vocab.json',\n './eng-tha-translation-fourth-model/merges.txt',\n './eng-tha-translation-fourth-model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"#zip the fourth model \n!zip -r ./eng-tha-translation-fourth-model.zip ./eng-tha-translation-fourth-model\n\nfrom IPython.display import FileLink\nFileLink(r'eng-tha-translation-fourth-model.zip')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:38:54.174811Z","iopub.execute_input":"2024-05-21T15:38:54.175246Z","iopub.status.idle":"2024-05-21T15:40:21.235326Z","shell.execute_reply.started":"2024-05-21T15:38:54.175208Z","shell.execute_reply":"2024-05-21T15:40:21.234204Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"  adding: eng-tha-translation-fourth-model/ (stored 0%)\n  adding: eng-tha-translation-fourth-model/special_tokens_map.json (deflated 85%)\n  adding: eng-tha-translation-fourth-model/generation_config.json (deflated 45%)\n  adding: eng-tha-translation-fourth-model/training_args.bin (deflated 51%)\n  adding: eng-tha-translation-fourth-model/model.safetensors (deflated 7%)\n  adding: eng-tha-translation-fourth-model/tokenizer_config.json (deflated 76%)\n  adding: eng-tha-translation-fourth-model/vocab.json (deflated 68%)\n  adding: eng-tha-translation-fourth-model/config.json (deflated 64%)\n  adding: eng-tha-translation-fourth-model/merges.txt (deflated 53%)\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/eng-tha-translation-fourth-model.zip","text/html":"<a href='eng-tha-translation-fourth-model.zip' target='_blank'>eng-tha-translation-fourth-model.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Example results after fourth train.","metadata":{}},{"cell_type":"code","source":"test_translation()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:44:22.765705Z","iopub.execute_input":"2024-05-21T15:44:22.766064Z","iopub.status.idle":"2024-05-21T15:44:36.387194Z","shell.execute_reply.started":"2024-05-21T15:44:22.766037Z","shell.execute_reply":"2024-05-21T15:44:36.386189Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  1\nEnter the text to translate:  i love studying\n"},{"name":"stdout","text":"Translated text: ฉันชอบการเรียน\n","output_type":"stream"}]},{"cell_type":"code","source":"test_translation()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:34:53.584986Z","iopub.execute_input":"2024-05-21T16:34:53.585607Z","iopub.status.idle":"2024-05-21T16:35:26.221916Z","shell.execute_reply.started":"2024-05-21T16:34:53.585573Z","shell.execute_reply":"2024-05-21T16:35:26.220990Z"},"trusted":true},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  2\nEnter the text to translate:  ฉันสอบเสร็จเมื่อวันจันทร์\n"},{"name":"stdout","text":"Translated text: I was so excited about it when it arrived.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_translation()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:38:35.416233Z","iopub.execute_input":"2024-05-21T16:38:35.417138Z","iopub.status.idle":"2024-05-21T16:38:54.752705Z","shell.execute_reply.started":"2024-05-21T16:38:35.417103Z","shell.execute_reply":"2024-05-21T16:38:54.751749Z"},"trusted":true},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  1\nEnter the text to translate:  I want more time.\n"},{"name":"stdout","text":"Translated text: ฉันต้องการเวลา\n","output_type":"stream"}]},{"cell_type":"code","source":"test_translation()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:39:01.564462Z","iopub.execute_input":"2024-05-21T16:39:01.564832Z","iopub.status.idle":"2024-05-21T16:39:15.036046Z","shell.execute_reply.started":"2024-05-21T16:39:01.564805Z","shell.execute_reply":"2024-05-21T16:39:15.035103Z"},"trusted":true},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  1\nEnter the text to translate:  How are you?\n"},{"name":"stdout","text":"Translated text: คุณเป็นอย่างไร\n","output_type":"stream"}]},{"cell_type":"code","source":"test_translation()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:39:27.654250Z","iopub.execute_input":"2024-05-21T16:39:27.654916Z","iopub.status.idle":"2024-05-21T16:40:00.119927Z","shell.execute_reply.started":"2024-05-21T16:39:27.654880Z","shell.execute_reply":"2024-05-21T16:40:00.118851Z"},"trusted":true},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  1\nEnter the text to translate:  I finished my exam last week\n"},{"name":"stdout","text":"Translated text: ฉันจบการสอบได้เมื่อแล้ว\n","output_type":"stream"}]},{"cell_type":"code","source":"test_translation()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:42:46.502303Z","iopub.execute_input":"2024-05-21T16:42:46.503203Z","iopub.status.idle":"2024-05-21T16:42:59.544721Z","shell.execute_reply.started":"2024-05-21T16:42:46.503169Z","shell.execute_reply":"2024-05-21T16:42:59.543646Z"},"trusted":true},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter translation direction (1 for EN-TH, 2 for TH-EN):  2\nEnter the text to translate:  ฉันอ่านหนังสือ\n"},{"name":"stdout","text":"Translated text: I read the book.\n","output_type":"stream"}]}]}